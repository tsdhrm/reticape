{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38594ce9-8c82-4332-8846-8d68c8628fe6",
   "metadata": {},
   "source": [
    "# MLP C: No Rounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9828bdee-bd3a-4f84-8643-b3194206c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 08:44:14.818286: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 08:44:14.954588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-22 08:44:14.954623: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-22 08:44:15.879147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-22 08:44:15.879349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-22 08:44:15.879367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import itertools\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a87a1-5529-4f4f-a311-513cdc364b67",
   "metadata": {},
   "source": [
    "# Read Data and Prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed216e51-c6fb-439a-bde5-059b15325c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_columns(dfm:pd.DataFrame, cols:list):\n",
    "    return dfm.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ac39d3f-c338-4a3b-8f09-51e98d4bf186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(ddir:str):\n",
    "    dataframe = pd.read_csv(ddir)\n",
    "    pruned_dataframe = prune_columns(dataframe, ['ImagesName'])\n",
    "    return pruned_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2ae630-f407-46a3-8117-22d58e56331a",
   "metadata": {},
   "source": [
    "# Split and Scale Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d196723a-b4d9-4f5e-a2fd-fcec21620412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9065739e-2345-4129-8302-842685141d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataframe:pd.DataFrame):\n",
    "    X = dataframe.drop(['Labels'], axis=1)\n",
    "    y = dataframe['Labels']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c393e6ee-e3bc-4ab6-837e-a3ead7f0b5ee",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e73c37ea-c77d-4b58-a63f-ff0a4c2bc811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(models: list,\n",
    "             X_train: np.array,\n",
    "             y_train: np.array,\n",
    "             X_test: np.array,\n",
    "             y_test: np.array,\n",
    "             epochs: int = 50,\n",
    "             verbose: int = 0) -> pd.DataFrame:\n",
    "    \n",
    "    # We'll store the results here\n",
    "    results = []\n",
    "    \n",
    "    def train(model: tf.keras.Sequential) -> dict:\n",
    "        # Change this however you want \n",
    "        # We're not optimizing this part today\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.binary_crossentropy,\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "            metrics=[\n",
    "                tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # Make predictions on the test set\n",
    "        preds = model.predict(X_test)\n",
    "        prediction_classes = [1 if prob > 0.5 else 0 for prob in np.ravel(preds)]\n",
    "        \n",
    "        model.evaluate(X_test, y_test, verbose=0)\n",
    "        model.save(f'/home/tsdhrm/Documents/retinacape/reticape/modelling/MLP/savedModel/180_cRounded/default_lr/nn_{model.name}.h5')\n",
    "        # Return evaluation metrics on the test set\n",
    "        return {\n",
    "            'model_name': model.name,\n",
    "            'test_accuracy': accuracy_score(y_test, prediction_classes),\n",
    "            'test_precision': precision_score(y_test, prediction_classes),\n",
    "            'test_recall': recall_score(y_test, prediction_classes),\n",
    "            'test_f1': f1_score(y_test, prediction_classes)\n",
    "        }\n",
    "    \n",
    "    # Train every model and save results\n",
    "    for model in models:\n",
    "        try:\n",
    "            print(model.name, end=' ... ')\n",
    "            res = train(model=model)\n",
    "            results.append(res)\n",
    "        except Exception as e:\n",
    "            print(f'{model.name} --> {str(e)}')\n",
    "        \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd5fe5d5-4894-477c-9ff7-486017d363b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_models(num_layers: int, min_nodes_per_layer: int,\\\n",
    "                 max_nodes_per_layer: int, node_step_size: int,\\\n",
    "                 input_shape: tuple, hidden_layer_activation: str = 'relu',\\\n",
    "                 num_nodes_at_output: int = 1, output_layer_activation: str = 'sigmoid') -> list:\n",
    "    \n",
    "    node_options = list(range(min_nodes_per_layer, max_nodes_per_layer + 1, node_step_size))\n",
    "    layer_possibilities = [node_options] * num_layers\n",
    "    layer_node_permutations = list(itertools.product(*layer_possibilities))\n",
    "    \n",
    "    models = []\n",
    "    for permutation in layer_node_permutations:\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.InputLayer(input_shape=input_shape))\n",
    "        model_name = ''\n",
    "        \n",
    "        for nodes_at_layer in permutation:\n",
    "            model.add(tf.keras.layers.Dense(nodes_at_layer, activation=hidden_layer_activation))\n",
    "            model_name += f'dense{nodes_at_layer}_'\n",
    "        \n",
    "        model.add(tf.keras.layers.Dense(num_nodes_at_output, activation=output_layer_activation))\n",
    "        model._name = model_name[:-1]\n",
    "        models.append(model)\n",
    "        \n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03dd2fd-985a-419d-890c-bc710341ff1e",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695d178-5d1b-436f-a7f9-1ea83cb7ae63",
   "metadata": {},
   "source": [
    "# Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7390b0de-6134-4037-a8f6-1a6faeb30bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_data_dir = '/home/tsdhrm/Documents/retinacape/reticape/exportedDataframe/180_c_rounded.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a40ed32-d0eb-45a5-83a5-dbabf4ae6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(features_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f3e733-a325-4cba-b2eb-559c7d9b0a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CDR</th>\n",
       "      <th>VCDR</th>\n",
       "      <th>RDR</th>\n",
       "      <th>I</th>\n",
       "      <th>S</th>\n",
       "      <th>N</th>\n",
       "      <th>T</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.4816</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>180</td>\n",
       "      <td>149</td>\n",
       "      <td>190</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.2994</td>\n",
       "      <td>0.2776</td>\n",
       "      <td>0.1948</td>\n",
       "      <td>175</td>\n",
       "      <td>197</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.2514</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>174</td>\n",
       "      <td>176</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.3790</td>\n",
       "      <td>0.3521</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>158</td>\n",
       "      <td>164</td>\n",
       "      <td>139</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.3778</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.1937</td>\n",
       "      <td>133</td>\n",
       "      <td>130</td>\n",
       "      <td>116</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CDR    VCDR     RDR    I    S    N    T  Labels\n",
       "142  0.4816  0.4835  0.1885  180  149  190  166       1\n",
       "112  0.2994  0.2776  0.1948  175  197  150  195       1\n",
       "162  0.2514  0.2493  0.1098  174  176  174  173       1\n",
       "55   0.3790  0.3521  0.1815  158  164  139  113       0\n",
       "60   0.3778  0.4118  0.1937  133  130  116  138       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d4fb2a0-4fcf-45e6-830f-18a9c31fee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0e4fb3-9d84-4130-8d26-01df0195c59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 08:44:17.655032: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-22 08:44:17.655080: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-22 08:44:17.655117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (fedora): /proc/driver/nvidia/version does not exist\n",
      "2022-11-22 08:44:17.655514: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "all_models = build_models(\\\n",
    "                          num_layers=3,#3\n",
    "                          min_nodes_per_layer=5,\n",
    "                          max_nodes_per_layer=30,\n",
    "                          node_step_size=5,\n",
    "                          input_shape=(7,)\\\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9638db17-80cd-4618-b82f-ed1bc06e3dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "dense5_dense5_dense25 ... WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc9f11bb370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc9f0e70160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "dense5_dense5_dense30 ... WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc9f0e712d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x7fc9f0e71fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "optimization_result = optimize(\\\n",
    "                               models=all_models,\\\n",
    "                               X_train=X_train_scaled,\\\n",
    "                               y_train=y_train,\\\n",
    "                               X_test=X_test_scaled,\\\n",
    "                               y_test=y_test,\n",
    "                               epochs=30 # 30, 50, 100\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf44b2fa-803f-4400-a560-a30089d7a5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>dense25_dense5_dense15</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.864865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>dense5_dense30_dense15</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.838710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>dense15_dense5_dense25</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>dense5_dense25_dense10</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>dense20_dense25_dense15</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>dense25_dense15_dense30</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dense5_dense5_dense10</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>dense15_dense30_dense15</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>dense20_dense15_dense25</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>dense10_dense10_dense20</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model_name  test_accuracy  test_precision  test_recall  \\\n",
       "146   dense25_dense5_dense15       0.861111        0.842105     0.888889   \n",
       "32    dense5_dense30_dense15       0.861111        1.000000     0.722222   \n",
       "76    dense15_dense5_dense25       0.833333        0.875000     0.777778   \n",
       "25    dense5_dense25_dense10       0.833333        0.928571     0.722222   \n",
       "134  dense20_dense25_dense15       0.833333        0.833333     0.833333   \n",
       "..                       ...            ...             ...          ...   \n",
       "161  dense25_dense15_dense30       0.638889        0.608696     0.777778   \n",
       "1      dense5_dense5_dense10       0.611111        0.642857     0.500000   \n",
       "104  dense15_dense30_dense15       0.611111        0.611111     0.611111   \n",
       "124  dense20_dense15_dense25       0.583333        0.578947     0.611111   \n",
       "45   dense10_dense10_dense20       0.583333        0.571429     0.666667   \n",
       "\n",
       "      test_f1  \n",
       "146  0.864865  \n",
       "32   0.838710  \n",
       "76   0.823529  \n",
       "25   0.812500  \n",
       "134  0.833333  \n",
       "..        ...  \n",
       "161  0.682927  \n",
       "1    0.562500  \n",
       "104  0.611111  \n",
       "124  0.594595  \n",
       "45   0.615385  \n",
       "\n",
       "[216 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimization_result.sort_values(by='test_accuracy', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reticape-9tvBW7jA-py3.10",
   "language": "python",
   "name": "reticape-9tvbw7ja-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
